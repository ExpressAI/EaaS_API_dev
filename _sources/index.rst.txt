.. Evaluation as a Service API documentation master file, created by
   sphinx-quickstart on Sat Sep  4 09:55:46 2021.
   You can adapt this file completely to your liking, but it should at least
   contain the root `toctree` directive.

Welcome to EaaS API's documentation!
=======================================================

.. toctree::
   :maxdepth: 2

   analysis
   metrics
   library




EaaS stands for "Evaluation as a Service". It is an open-source framework for facilitating evaluations for various NLP tasks. It offers a wide variety of functionalities including

* Basic scoring functionality for system outputs.
* Fine-grained evaluation
* To be continued

Getting Started
----------------------
To install EaaS, simply run::

   pip install eaas

To use the API, run the following as a simple example::

   from eaas import Client
   client = Client()

   # To use this API for scoring, you need to format your input as list of dictionary. Each dictionary consists of `src` (string, optional), `refs` (list of string, optional) and `hypo` (string, required). `src` and `refs` are optional based on the metrics you want to use. Please do not conduct any preprocessing on `src`, `refs` or `hypo`, we expect normal-cased detokenized texts. All preprocessing steps are taken by the metrics. Below is a simple example.

   inputs = [{"src": "This is the source.",
              "refs": ["This is the reference one.", "This is the reference two."],
              "hypo": "This is the generated hypothesis."}]
   metrics = ["bleu", "chrf"] # Can be None for simplicity if you consider using all metrics

   score_dic = client.score(inputs, metrics) # inputs is a list of Dict, metrics is metric list

The output is like::

   {
     'bleu': [32.46679154750991],  # Sample-level scores. A list of scores one for each sample.
     'corpus_bleu': 32.46679154750991, # Corpus-level score.
     'chrf': [38.56890099861521],
     'corpus_chrf': 38.56890099861521
   }





Existing Metrics
-------------------
* `bart_score_summ`: This is used for text summarization.
* :bart_score_mt: This is used for machine translation.
* "bert_score":
* "bleu":
* "chrf":
* "comet":
* "comet_qe":
* "mover_score":
* "prism":
* "prism_qe":
* "rouge":


Indices and tables
==================

* :ref:`genindex`
* :ref:`modindex`
* :ref:`search`
